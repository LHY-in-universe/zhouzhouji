---
mdate: 2026-01-28 17:51:36
---
Figure 02和Helix技术分析 
整体采用三层架构，最上层采用多模态大模型进行任务规划，将要执行的任务拆解为action粒度，方便指导第二层的VLA模型。第二层采用快慢系统（Helix），用于完成具体的动作。底层则是硬件控制器，用于执行动作。

Helix 2.0
每个系统都在它自己的自然时间尺度上运行。系统2（S2）慢慢地思考目标：解释场景、理解语言、以及编排行为。系统1（S1）快速思考，把感知转化为全身关节目标，频率是200赫兹。系统0（S0）以1千赫兹的速度执行，处理全身的平衡、接触和协调。它们一起构成了从像素到扭矩的一个紧密集成的层级结构。

LingBot VLA
Mixture-of-Transformers架构: 不像传统Transformer那样把所有信息（图像、文本、动作）都塞进同一个处理流程。而是像 “多个专家（Transformers）合作” ，每个专家负责处理特定的模态，但彼此间能进行高效的通信。
深度信息蒸馏：引入了一个专门训练好的深度估计模型（LingBot-Depth）。它不是简单地把深度图作为额外输入，而是采用一种更优雅的“知识蒸馏”方式。

ViT 外接 MLP 进行多分类 
ViT MLP LLM 进行 2b 8b 模型融合, 子母模型分步推理