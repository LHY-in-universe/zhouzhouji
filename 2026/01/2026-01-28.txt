---
mdate: 2026-01-28 14:12:45
---
Figure 02和Helix技术分析 
整体采用三层架构，最上层采用多模态大模型进行任务规划，将要执行的任务拆解为action粒度，方便指导第二层的VLA模型。第二层采用快慢系统（Helix），用于完成具体的动作。底层则是硬件控制器，用于执行动作。

LingBot VLA
Mixture-of-Transformers架构: 不像传统Transformer那样把所有信息（图像、文本、动作）都塞进同一个处理流程。而是像 “多个专家（Transformers）合作” ，每个专家负责处理特定的模态，但彼此间能进行高效的通信。
深度信息蒸馏：引入了一个专门训练好的深度估计模型（LingBot-Depth）。它不是简单地把深度图作为额外输入，而是采用一种更优雅的“知识蒸馏”方式。
